{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS295B F18: Homework 7\n",
    "## Differentially Private Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Before you start, download the example dataset and ensure that all cells in this notebook execute without error. If you have trouble getting the notebook to run, please post a question on Piazza.\n",
    "\n",
    "To ensure that the notebook runs, I've defined a function `your_code_here()` that simply returns the number `1`. Whenever you see a call to this function, you should replace it with code you have written. Please make sure all cells of your notebook run without error before submitting the assignment. If you have not completed all the questions, leave calls to `your_code_here()` in place or insert dummy values so that the cell does not throw an error when it runs.\n",
    "\n",
    "To help you arrive at the correct solution, I have left the value computed by my solution in the uploaded version of this notebook. You can refer to these example results by viewing the notebook on Github. If you re-run the cell after downloading the notebook, the results will disappear (because the notebook no longer contains the code that generated them). Your solutions should produce results similar to the ones in the uploaded notebook.\n",
    "\n",
    "When answering non-code questions, feel free to use a comment, or put the cell in Markdown mode and use Markdown.\n",
    "\n",
    "The assignment is due by 11:59pm on Monday, November 12. When you have finished your assignment, submit it via Blackboard under the assignment \"Homework 6.\" For questions on grading and submitting assignments, refer to the course webpage or email the instructor.\n",
    "\n",
    "The dataset files you'll need are available here:\n",
    "\n",
    "- [`adult_processed_x`](https://github.com/jnear/cs295-data-privacy/blob/master/slides/adult_processed_x.npy)\n",
    "- [`adult_processed_y`](https://github.com/jnear/cs295-data-privacy/blob/master/slides/adult_processed_y.npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration Statement\n",
    "\n",
    "In the cell below, write your collaboration statement. This statement should describe all collaborations, even high-level ones (e.g. \"I discussed my general approach for answering question 3 with Josh\"). High-level collaborations of this kind are allowed as long as they are described; copying of answers or code is not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your collaboration statement here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Some useful utilities\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "def z_clip(xs, b):\n",
    "    return [min(x, b) for x in xs]\n",
    "\n",
    "def clip(xs, upper, lower):\n",
    "    return [max(min(x, upper), lower) for x in xs]\n",
    "\n",
    "def gaussian_mech_vec(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon, size=len(v))\n",
    "\n",
    "def g_clip(v):\n",
    "    n = np.linalg.norm(v, ord=2)\n",
    "    if n > 1:\n",
    "        return v / n\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def your_code_here():\n",
    "    return 1\n",
    "\n",
    "def test(msg, value, expected):\n",
    "    if value == expected:\n",
    "        print(f\"{msg}: {value}, as expected\")\n",
    "    else:\n",
    "        print(f\"{msg}: OH NO! Got {value}, but expected {expected}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('adult_processed_x.npy')\n",
    "y = np.load('adult_processed_y.npy')\n",
    "\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(theta, xi):\n",
    "    label = np.sign(xi @ theta)\n",
    "    return label\n",
    "\n",
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the average logistic loss function.\n",
    "def loss(theta, x, y, lambda_param=0):\n",
    "    exponent = - y * (x.dot(theta))\n",
    "    regularization = (lambda_param/2) * np.sum(theta*theta)\n",
    "    return np.sum(np.log(1+np.exp(exponent))) / x.shape[0]\n",
    "\n",
    "# This is the average gradient of the logistic loss\n",
    "# The gradient is a vector that indicates in which direction the loss function is increasing fastest\n",
    "def gradient(theta, x, y, lambda_param=0):\n",
    "    exponent = y * (x.dot(theta))\n",
    "    gradient_loss = - (np.transpose(x) @ (y / (1+np.exp(exponent)))) / (x.shape[0])\n",
    "    regularization = lambda_param * theta\n",
    "    return gradient_loss + regularization\n",
    "\n",
    "# our measure of accuracy is just % correct of the test set\n",
    "def accuracy(theta, X, y):\n",
    "    return np.sum([predict(theta, xi) for xi in X] == y) / y.shape[0]\n",
    "\n",
    "# This is gradient descent with a *learning rate* \"eta\"\n",
    "def gradient_descent(X_train, y_train, iterations, status = False):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    eta = 1.0\n",
    "    lambda_param = 0.001\n",
    "\n",
    "    for i in range(iterations):\n",
    "        theta = theta - eta * gradient(theta, X_train, y_train, lambda_param)\n",
    "        if status and i % int(iterations / 5) == 0:\n",
    "            print(f\"Iteration {i}: loss = {loss(theta, X_train, y_train, lambda_param)}\")\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss = 0.549109439168421\n",
      "Iteration 200: loss = 0.37016593673141646\n",
      "Iteration 400: loss = 0.36183446200459896\n",
      "Iteration 600: loss = 0.3580948174586848\n",
      "Iteration 800: loss = 0.3560122225542519\n",
      "Final accuracy: 0.8316010614772225\n"
     ]
    }
   ],
   "source": [
    "theta = gradient_descent(X_train, y_train, 1000, True)\n",
    "acc = accuracy(theta, X_test, y_test)\n",
    "print(f\"Final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Implement a function `dp_gradient_descent` that performs differentially private gradient descent by adding noise to the gradient at each iteration. Your function should take additional arguments $\\epsilon$ and $\\delta$, and should have an **overall** privacy cost of $(\\epsilon, \\delta)$-differential privacy.\n",
    "\n",
    "*Hint*: Use `gaussian_mech_vec`, defined above, to add noise.\n",
    "\n",
    "*Hint*: Use advanced composition to bound the total privacy cost. Start with the total privacy cost of $k$-fold adaptive composition under advanced composition, then solve for $\\epsilon_i$, the privacy cost per iteration. Use this result to set the per-iteration value of `epsilon`, and similar for `delta`.\n",
    "\n",
    "*Hint*: Don't forget clipping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.01, final accuracy: 0.6167624944714728\n",
      "Epsilon = 0.1, final accuracy: 0.731203007518797\n",
      "Epsilon = 1.0, final accuracy: 0.8032950022114109\n"
     ]
    }
   ],
   "source": [
    "def dp_gradient_descent(X_train, y_train, iterations, epsilon, delta):\n",
    "    return your_code_here()\n",
    "\n",
    "delta = 1e-5\n",
    "X_test_clip = np.array([g_clip(x) for x in X_test])\n",
    "\n",
    "for epsilon in [0.01, 0.1, 1.0]:\n",
    "    theta = dp_gradient_descent(X_train, y_train, 500, epsilon, delta)\n",
    "    acc = accuracy(theta, X_test_clip, y_test)\n",
    "    print(f\"Epsilon = {epsilon}, final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (5 points)\n",
    "\n",
    "In 2-5 sentences, argue that your implementation of `dp_gradient_descent` satisfies $(\\epsilon, \\delta)$-differential privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Implement a function `zcdp_gradient_descent` that performs differentially private gradient descent by adding noise to the gradient at each iteration. Your function should take an additional argument $\\rho$, and should have an **overall** privacy cost of $\\rho$-zero concentrated differential privacy. You will also have to implement `gaussian_mech_vec_zcdp`, the vector-valued gaussian mechanism for zCDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho = 1e-05, final accuracy: 0.7622733303847855\n",
      "rho = 0.0001, final accuracy: 0.8143520566121185\n",
      "rho = 0.001, final accuracy: 0.8198805838124723\n"
     ]
    }
   ],
   "source": [
    "def gaussian_mech_vec_zcdp(v, sensitivity, rho):\n",
    "    return your_code_here()\n",
    "\n",
    "def zcdp_gradient_descent(X_train, y_train, iterations, rho):\n",
    "    return your_code_here()\n",
    "\n",
    "X_test_clip = np.array([g_clip(x) for x in X_test])\n",
    "\n",
    "for rho in [0.00001, 0.0001, 0.001]:\n",
    "    theta = zcdp_gradient_descent(X_train, y_train, 500, rho)\n",
    "    acc = accuracy(theta, X_test_clip, y_test)\n",
    "    print(f\"rho = {rho}, final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (5 points)\n",
    "\n",
    "Implement a function `convert_zCDP_eps_delta` that converts a $\\rho$-zCDP privacy bound to a $(\\epsilon,\\delta)$-differential privacy bound, given a target $\\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho = 1e-05, epsilon = 0.021469660262893472, final accuracy: 0.7585139318885449\n",
      "rho = 0.0001, epsilon = 0.06796140424415112, final accuracy: 0.7999778858911986\n",
      "rho = 0.001, epsilon = 0.21559660262893474, final accuracy: 0.8155683325961963\n"
     ]
    }
   ],
   "source": [
    "def convert_zCDP_eps_delta(rho, delta):\n",
    "    return your_code_here()\n",
    "\n",
    "delta = 1e-5\n",
    "\n",
    "for rho in [0.00001, 0.0001, 0.001]:\n",
    "    theta = zcdp_gradient_descent(X_train, y_train, 500, rho)\n",
    "    acc = accuracy(theta, X_test_clip, y_test)\n",
    "    epsilon = convert_zCDP_eps_delta(rho, delta)\n",
    "    print(f\"rho = {rho}, epsilon = {epsilon}, final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (10 points)\n",
    "\n",
    "Implement a function `output_perturbation` that performs differentially private machine learning by adding noise to the **final model** (i.e. **output perturbation**). Your function should take additional arguments $\\epsilon$ and $\\delta$, and should have an **overall** privacy cost of $(\\epsilon,\\delta)$-differential privacy.\n",
    "\n",
    "*Hint*: use `gradient_descent` to do the machine learning, then `gaussian_mech_vec` to add noise to the `theta` which comes out. Recall the sensitivity of ERM from class.\n",
    "\n",
    "**Note**: as mentioned in class, this approach does *not* actually satisfy differential privacy unless `gradient_descent` reaches the true minimizer. For this problem, assume that it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.01, final accuracy: 0.49159663865546216\n",
      "Epsilon = 0.1, final accuracy: 0.7533171163202123\n",
      "Epsilon = 1.0, final accuracy: 0.8176691729323309\n"
     ]
    }
   ],
   "source": [
    "def output_perturbation(X_train, y_train, iterations, epsilon, delta):\n",
    "    return your_code_here()\n",
    "\n",
    "delta = 1e-5\n",
    "X_test_clip = np.array([g_clip(x) for x in X_test])\n",
    "\n",
    "for epsilon in [0.01, 0.1, 1.0]:\n",
    "    theta = output_perturbation(X_train, y_train, 500, epsilon, delta)\n",
    "    acc = accuracy(theta, X_test_clip, y_test)\n",
    "    print(f\"Epsilon = {epsilon}, final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (5 points)\n",
    "\n",
    "How could `gradient_descent` be re-defined so that `output_perturbation` actually leaks information about a single sample in the training data? (i.e. how could `output_perturbation` violate privacy in a severe way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (5 points)\n",
    "Which of the approaches you have implemented is likely to yield the best accuracy in practice? (ignore the non-privacy of `output_perturbation` for this question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
